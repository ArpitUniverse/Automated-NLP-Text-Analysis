{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08i7iQH7VA2t"
      },
      "outputs": [],
      "source": [
        "# Install the Google Generative AI library\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# analyze sentiment function\n",
        "def analyze_sentiment(input_text, category, explanation, model):\n",
        "\n",
        "    # check if a category is specified, otherwise default to positive, negative, neutral\n",
        "    category = category if category else 'positive, negative, neutral'\n",
        "\n",
        "    # check if explanation is required\n",
        "    explanation_text = 'short explanation: ' if explanation else 'no explanation'\n",
        "\n",
        "    # question to be asked\n",
        "    question = f'''Given the input text, perform sentiment analysis on it\n",
        "    category: {category}\n",
        "    {input_text}\n",
        "    {explanation_text}\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for topic modeling\n",
        "def classify_topic(input_text, topics, explanation, model):\n",
        "\n",
        "    # check if topics are specified, otherwise default to a placeholder\n",
        "    topics = f'''topics are: {topics}''' if topics else '''topics are: story, horror, comedy'''\n",
        "\n",
        "    # check if explanation is required\n",
        "    explanation_text = 'short explanation: ' if explanation else 'no explanation'\n",
        "\n",
        "    # question to be asked\n",
        "    question = f'''Given the input text, perform Topic Classification on it\n",
        "    {topics}\n",
        "    {input_text}\n",
        "    {explanation_text}\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "# function for spam detection\n",
        "def detect_spam(input_text, category, explanation, model):\n",
        "    # check if a category is specified, otherwise default to spam, not_spam, unknown\n",
        "    category = category if category else 'spam, not_spam, unknown'\n",
        "\n",
        "    # check if explanation is required\n",
        "    explanation_text = 'provide short explanation' if explanation else 'no explanation'\n",
        "\n",
        "    # question to be asked\n",
        "    question = f'''Given the input text, perform spam detection on it\n",
        "    {category}\n",
        "    {input_text}\n",
        "    {explanation_text}\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for NER tagging\n",
        "def detect_ner(input_text, ner_tags, model):\n",
        "    # check if NER tags are specified, otherwise default to a placeholder\n",
        "    ner_tags = ner_tags if ner_tags else 'person, location, date, number, organization, time, money, percent, facility, product, event, language, law, ordinal, misc, quantity, cardinal'\n",
        "\n",
        "    # question to be asked\n",
        "    question = f'''Given the input text, perform NER detection on it\n",
        "    NER Tags are: {ner_tags}\n",
        "    {input_text}\n",
        "    answer must be in the format\n",
        "    word: entity\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "# function for POS tagging\n",
        "def detect_pos(input_text, pos_tags, model):\n",
        "    # check if POS tags are specified, otherwise default to a placeholder\n",
        "    pos_tags = pos_tags if pos_tags else 'noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, determiner, cardinal, foreign, number, date, time, ordinal, money, percent, symbol, punctuation, emoticon, hashtag, email, url, mention, phone, ip, cashtag, entity, noun_phrase, verb_phrase, adjective_phrase, adverb_phrase, pronoun_phrase, preposition_phrase, conjunction_phrase, interjection_phrase, determiner_phrase, cardinal_phrase, foreign_phrase, number_phrase, date_phrase, time_phrase, ordinal_phrase, money_phrase, percent_phrase, symbol_phrase, punctuation_phrase, emoticon_phrase, hashtag_phrase, email_phrase, url_phrase, mention_phrase, phone_phrase, ip_phrase, cashtag_phrase, entity_phrase'\n",
        "\n",
        "    # question to be asked\n",
        "    question = f'''Given the input text, perform POS detection on it\n",
        "    POS Tags are: {pos_tags}\n",
        "    {input_text}\n",
        "    answer must be in the format\n",
        "    word: POS\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for machine translation\n",
        "def translate_text(input_text, source_language, target_language, model):\n",
        "    # question to be asked\n",
        "    question = f'''Translate the below input text from {source_language} to {target_language}:\n",
        "    {input_text}\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for text summarization\n",
        "def summarize_text(input_text, summary_length, model):\n",
        "    # question to be asked\n",
        "    question = f'''Summarize the below input text of {summary_length} length:\n",
        "    {input_text}\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for question answering\n",
        "def answer_question(question_text, model):\n",
        "    # question to be asked\n",
        "    question = f'''Answer the following question:\n",
        "    {question_text}\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for text generation\n",
        "def generate_text(prompt, generation_length, model):\n",
        "    # question to be asked\n",
        "    question = f'''Generate a {generation_length} text,\n",
        "    {prompt}\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "# function for Semantic Role Labeling (SRL)\n",
        "def perform_srl(input_text, model):\n",
        "    # question to be asked\n",
        "    question = f'''Given the input text, perform Semantic Role Labeling detection on it\n",
        "    {input_text}\n",
        "    Output must be\n",
        "    Predicate:\n",
        "    Roles:\n",
        "    -\n",
        "    -\n",
        "    -\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for intent recognition\n",
        "def recognize_intent(input_text, model):\n",
        "    # question to be asked\n",
        "    question = f'''Given the input text, perform Intent Recognition detection on it\n",
        "    {input_text}\n",
        "    Output must be\n",
        "    Intent:\n",
        "    '''\n",
        "\n",
        "    # generate response\n",
        "    response = model.generate_content(question)\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# function for paraphrase detection\n",
        "def paraphrasing_detection(input_text, explanation, model):\n",
        "\n",
        "    # Check if explanation is required\n",
        "    explanation_text = 'short explanation: ' if explanation else 'no explanation'\n",
        "\n",
        "    # Question to be asked for determining paraphrasing\n",
        "    question = f'''Given the input text, determine if two sentences are paraphrases of each other.\n",
        "    Sentence 1: {input_text[0]}\n",
        "    Sentence 2: {input_text[1]}\n",
        "    Answer must be 'yes' or 'no'.\n",
        "    {explanation_text}\n",
        "    '''\n",
        "\n",
        "    # Generate response\n",
        "    response = model.generate_content(question)\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "94MQUIKPVFds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Google Generative AI library\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Initialize the GenerativeModel with 'gemini-pro'\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Configure the library with your API key\n",
        "genai.configure(api_key=\"AIzaSyBsORXJAvvmFP-ijm350ceH6T-br4VOM8E\")"
      ],
      "metadata": {
        "id": "-clTBf8HVeHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from core_nlp import answer_question\n",
        "\n",
        "question_text = \"Rolling was done after casting , what is the order of the process?\"\n",
        "\n",
        "answer_result = answer_question(question_text, model=model)\n",
        "\n",
        "print(answer_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Yr-WBRgUVUPv",
        "outputId": "e65ddb94-8276-47a3-b876-39c7d7993911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Mold Preparation\n",
            "2. Melting\n",
            "3. Casting\n",
            "4. Rolling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fitz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bfUieffgXCjp",
        "outputId": "17191d8f-6205-48c1-e029-4066e1057f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl.metadata (816 bytes)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.9.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.3.2)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.2.2)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.13.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.2.0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (6.4.5)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (4.12.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.4.2)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting simplejson>=3.8.0 (from nipype->fitz)\n",
            "  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting traits!=5.0,>=4.6 (from nipype->fitz)\n",
            "  Downloading traits-6.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.16.1)\n",
            "Collecting etelemetry>=0.2.0 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting looseversion!=1.2 (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting puremagic (from nipype->fitz)\n",
            "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.2)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (5.3.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.32.3)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.2.0->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.16.0)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2024.8.30)\n",
            "Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading nipype-1.9.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyxnat-1.6.2-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traits-6.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: configobj\n",
            "  Building wheel for configobj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.9-py2.py3-none-any.whl size=35617 sha256=468a24ec51e63410ca7b38ecba02d488581a83ecd67f78081e7c4815647b762b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6c/03/6c5e3cf1a6e4b9e2fc5c4409be4abc5a8268bd9c878739cb32\n",
            "Successfully built configobj\n",
            "Installing collected packages: puremagic, looseversion, traits, simplejson, isodate, configparser, configobj, ci-info, rdflib, pyxnat, etelemetry, prov, nipype, fitz\n",
            "Successfully installed ci-info-0.3.0 configobj-5.0.9 configparser-7.1.0 etelemetry-0.3.1 fitz-0.0.1.dev2 isodate-0.6.1 looseversion-1.3.0 nipype-1.9.0 prov-2.0.1 puremagic-1.28 pyxnat-1.6.2 rdflib-6.3.2 simplejson-3.19.3 traits-6.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports"
                ]
              },
              "id": "5b98ec14f84f420d996a246d889cf4fd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhU994HcXV67",
        "outputId": "e3285800-faa6-45a1-cbf5-6dab2c743454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.24.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Initialize the GenerativeModel with 'gemini-pro'\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "genai.configure(api_key=\"AIzaSyBsORXJAvvmFP-ijm350ceH6T-br4VOM8E\")  # Replace with your API key\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    # Open the PDF file\n",
        "    with fitz.open(pdf_path) as pdf:\n",
        "        # Iterate over each page\n",
        "        for page_num in range(pdf.page_count):\n",
        "            page = pdf[page_num]\n",
        "            text += page.get_text()  # Extract text from each page\n",
        "    return text\n",
        "\n",
        "# Function for question answering with context\n",
        "def answer_question_with_context(question_text, context_text, model):\n",
        "    # Combine the context with the question for a more informed answer\n",
        "    question = f'''Based on the provided research paper, answer the following question:\n",
        "    Research Paper: {context_text}\n",
        "    Question: {question_text}\n",
        "    '''\n",
        "    # Generate response\n",
        "    response = model.generate_content(question)\n",
        "    return response.text.strip()\n",
        "\n",
        "# Main function to load PDF, extract text, and answer questions\n",
        "def main(pdf_path, question_text):\n",
        "    research_paper_text = extract_text_from_pdf(pdf_path)\n",
        "    answer_result = answer_question_with_context(question_text, research_paper_text, model=model)\n",
        "\n",
        "    return answer_result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_FYLEobOV-aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/RS 50.pdf\"\n",
        "question_text = \"Give me the mechanical properties ?\"\n",
        "answer = main(pdf_path, question_text)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "1k7Op05DXQPL",
        "outputId": "1bdd5c9c-97a5-42b8-d764-b4c68ae3e842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Mechanical Properties of CoCrFeNiAl0.5Ti0.1 High Entropy Alloy Rod:**\n",
            "\n",
            "* **Nanoindentation Study:**\n",
            "    * Precipitate phase exhibits greater hardness compared to the matrix.\n",
            "    * Surface consists of undulating hills and valleys due to differences in hardness and modulus of elasticity between the two phases.\n",
            "\n",
            "* **Tensile Properties:**\n",
            "    * Room temperature: Tensile strength of 1146 MPa and elongation of 16.7%.\n",
            "    * 200 K: Tensile strength of 1204 MPa and elongation of 18.3%.\n",
            "    * 77 K: Tensile strength of 1423 MPa and elongation of 14.2%.\n",
            "    * Lower temperatures enhance ductility due to a shift in deformation mechanism from dislocation slip to a combination of dislocation slip and nanotwinning.\n",
            "    * Higher temperatures (873 K and above) lead to a decrease in tensile strength.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9Fqdp_PVM3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LZ5U_rCoUNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}